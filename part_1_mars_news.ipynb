{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 12 Challenge\n",
    "## Deliverable 1: Scrape Titles and Preview Text from Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Splinter and BeautifulSoup\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Visit the Website\n",
    "\n",
    "1. Use automated browsing to visit the [Mars NASA news site](https://redplanetscience.com). Inspect the page to identify which elements to scrape.\n",
    "\n",
    "      > **Hint** To identify which elements to scrape, you might want to inspect the page by using Chrome DevTools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the Mars NASA news site: https://redplanetscience.com\n",
    "url = 'https://redplanetscience.com/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Scrape the Website\n",
    "\n",
    "Create a Beautiful Soup object and use it to extract text elements from the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Beautiful Soup object\n",
    "html = browser.html\n",
    "soup = soup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all the text elements\n",
    "all_text = soup.find_all('div', class_='list_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Store the Results\n",
    "\n",
    "Extract the titles and preview text of the news articles that you scraped. Store the scraping results in Python data structures as follows:\n",
    "\n",
    "* Store each title-and-preview pair in a Python dictionary. And, give each dictionary two keys: `title` and `preview`. An example is the following:\n",
    "\n",
    "  ```python\n",
    "  {'title': \"Mars Rover Begins Mission!\", \n",
    "        'preview': \"NASA's Mars Rover begins a multiyear mission to collect data about the little-explored planet.\"}\n",
    "  ```\n",
    "\n",
    "* Store all the dictionaries in a Python list.\n",
    "\n",
    "* Print the list in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the dictionaries\n",
    "# Create an empty list to store the dictionaries\n",
    "articles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists for titles articles and previews\n",
    "t_list = []\n",
    "p_list = []\n",
    "\n",
    "# Loop through the text elements\n",
    "titles = soup.find_all('div', class_=\"content_title\")\n",
    "for each in titles:\n",
    "    title = each.text\n",
    "    t_list.append(title)\n",
    "\n",
    "# Extract the title and preview text from the elements\n",
    "previews = soup.find_all('div', class_=\"article_teaser_body\")\n",
    "for each in previews:\n",
    "    preview = each.text    \n",
    "    p_list.append(preview)\n",
    "\n",
    "\n",
    "# Store each title and preview pair in a dictionary\n",
    "# Add the dictionary to the list\n",
    "for title, preview in zip(t_list, p_list):\n",
    "    dict = {'title': title, 'preview': preview}\n",
    "    articles.append(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'NASA Invites Public to Share Excitement of Mars 2020 Perseverance Rover Launch', 'preview': 'There are lots of ways to participate in the historic event, which is targeted for July 30.'}, {'title': \"NASA's Briefcase-Size MarCO Satellite Picks Up Honors\", 'preview': 'The twin spacecraft, the first of their kind to fly into deep space, earn a Laureate from Aviation Week & Space Technology.'}, {'title': 'The MarCO Mission Comes to an End', 'preview': 'The pair of briefcase-sized satellites made history when they sailed past Mars in 2019.'}, {'title': 'NASA, ULA Launch Mars 2020 Perseverance Rover Mission to Red Planet', 'preview': \"The agency's Mars 2020 mission is on its way. It will land at Jezero Crater in about seven months, on Feb. 18, 2021. \"}, {'title': 'MOXIE Could Help Future Rockets Launch Off Mars', 'preview': \"NASA's Perseverance rover carries a device to convert Martian air into oxygen that, if produced on a larger scale, could be used not just for breathing, but also for fuel.\"}, {'title': \"Q&A with the Student Who Named Ingenuity, NASA's Mars Helicopter\", 'preview': 'As a longtime fan of space exploration, Vaneeza Rupani appreciates the creativity and collaboration involved with trying to fly on another planet.'}, {'title': 'NASA to Hold Mars 2020 Perseverance Rover Launch Briefing', 'preview': \"Learn more about the agency's next Red Planet mission during a live event on June 17.\"}, {'title': \"NASA's Mars 2020 Heads Into the Test Chamber\", 'preview': 'In this time-lapse video taken at JPL, engineers move the Mars 2020 rover into a large vacuum chamber for testing in Mars-like environmental conditions.'}, {'title': \"NASA InSight's 'Mole' Is Out of Sight\", 'preview': \"Now that the heat probe is just below the Martian surface, InSight's arm will scoop some additional soil on top to help it keep digging so it can take Mars' temperature.\"}, {'title': 'NASA Updates Mars 2020 Mission Environmental Review', 'preview': 'NASA and the Department of Energy have completed a more detailed risk analysis for the Mars 2020 rover launch from Florida.'}, {'title': \"How NASA's Perseverance Mars Team Adjusted to Work in the Time of Coronavirus \", 'preview': 'Like much of the rest of the world, the Mars rover team is pushing forward with its mission-critical work while putting the health and safety of their colleagues and community first.'}, {'title': \"What's Mars Solar Conjunction, and Why Does It Matter?\", 'preview': 'NASA spacecraft at Mars are going to be on their own for a few weeks when the Sun comes between Mars and Earth, interrupting communications.'}, {'title': \"Hear Audio From NASA's Perseverance As It Travels Through Deep Space\", 'preview': \"The first to be rigged with microphones, the agency's latest Mars rover picked up the subtle sounds of its own inner workings during interplanetary flight.\"}, {'title': \"A Year of Surprising Science From NASA's InSight Mars Mission\", 'preview': \"A batch of new papers summarizes the lander's findings above and below the surface of the Red Planet.\"}, {'title': 'Mars 2020 Unwrapped and Ready for More Testing', 'preview': \"In time-lapse video, bunny-suited engineers remove the inner layer of protective foil on NASA's Mars 2020 rover after it was relocated for testing.\"}]\n"
     ]
    }
   ],
   "source": [
    "# Print the list to confirm success\n",
    "print(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Step 4: Export the Data\n",
    "\n",
    "Optionally, store the scraped data in a file or database (to ease sharing the data with others). To do so, export the scraped data to either a JSON file or a MongoDB database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data to JSON\n",
    "scraped_data = json.dumps(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data to MongoDB\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
